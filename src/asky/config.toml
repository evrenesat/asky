# asky Configuration File
# This file defines general settings, API endpoints, user shortcuts, and model configurations.

# --- General Settings ---
[general]
# Name of the environment variable that stores the path to the SQLite history database.
# Default if not set: SEARXNG_HISTORY_DB_PATH
db_path_env_var = "SEARXNG_HISTORY_DB_PATH"

# Logging Configuration
# Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_level = "INFO"
# Log file path. Defaults to ~/.config/asky/asky.log
log_file = "~/.config/asky/asky.log"

# Maximum length of the query and answer summaries shown in 'asky -H'.
query_summary_max_chars = 40
answer_summary_max_chars = 200

# Threshold for using full query vs summary in --continue-chat mode.
# If query length is below this, it's used as is.
continue_query_threshold = 160

# URL of your SearXNG instance.
searxng_url = "http://localhost:8888"

# Search provider to be used: "searxng" or "serper"
search_provider = "searxng"

# URL of the Serper API.
serper_api_url = "https://google.serper.dev/search"

# Name of the environment variable that stores the Serper API key.
serper_api_key_env = "SERPER_API_KEY"

# Maximum number of turns (tool calls) allowed in a single conversation loop.
max_turns = 20

# Timeout for API requests in seconds
request_timeout = 60

# Default context size (if not specified in the model configuration)
default_context_size = 4096

# Default model used when no model is specified via CLI (-m).
default_model = "gf"

# Model used specifically for internal text summarization tasks.
summarization_model = "lfm"

# User-Agent string to be used for search and content retrieval requests.
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"

# Specific User-Agent string for LLM API requests.
# Some providers only accept specific user agents for certain subscriptions types.
llm_user_agent = "asky/1.0.0"

# --- Limits & Timeouts ---
[limits]
# Maximum number of links returned from get_url_details to prevent context overflow.
max_url_detail_links = 50

# Maximum snippet length in search results.
search_snippet_max_chars = 400

# Maximum recursion depth for expanding slash commands.
query_expansion_max_depth = 5

# LLM API retry settings
max_retries = 10
initial_backoff = 2
max_backoff = 60

# Search and fetch timeouts in seconds
search_timeout = 20
fetch_timeout = 20

# --- API Definitions ---
# Define reusable API endpoints and authentication details here.
# For each section [api.NAME]:
#   url: The base URL for the chat completions endpoint.
#   api_key_env: (Recommended) Name of the environment variable containing the API key.
#   api_key: (Optional) The API key directly. Takes precedence over api_key_env if both are missing.

[api.gemini]
url = "https://generativelanguage.googleapis.com/v1beta/chat/completions"
api_key_env = "GOOGLE_API_KEY"


[api.anthropic]
url = "https://api.anthropic.com/v1/messages"
api_key_env = "ANTHROPIC_API_KEY"


[api.openai]
url = "https://api.openai.com/v1/chat/completions"
api_key_env = "OPENAI_API_KEY"


[api.openrouter]
url = "https://openrouter.ai/api/v1/chat/completions"
api_key_env = "OPENROUTER_API_KEY"


[api.lmstudio]
url = "http://localhost:1234/v1/chat/completions"
api_key = "lm-studio"


[api.zai]
url = "https://api.z.ai/api/paas/v4/chat/completions"
api_key_env = "ZAI_API_KEY"


# --- User Prompts (Shortcuts) ---
# Define shortcuts that can be used via '/key' in the CLI.
# Example: 'ask /gn' will be expanded to the prompt below.
[user_prompts]
gn = "Give me latest news from The Guardian, use https://www.theguardian.com/europe"
wh = "how is weather in "
ex = "Explain this: /cp"

# --- User defined tools ---
# These tools allow you to expose CLI commands to the LLM.
# Use {parameter_name} in the command to inject arguments, or they will be appended.
[tool.list_dir]
command = "ls {flags} {path}"
description = "List the contents of a directory."
parameter_type = "object"
[tool.list_dir.parameters]
type = "object"
required = ["path"]

[tool.list_dir.parameters.properties.path]
type = "string"
default = "."

[tool.list_dir.parameters.properties.flags]
type = "string"
default = "-la"


# [tool.grep_search]
# command = "grep -r --exclude-dir={.venv,node_modules} {pattern} {path}"
# description = "Search for a pattern in files recursively."

# [tool.grep_search.parameters]
# type = "object"
# required = ["pattern"]

# [tool.grep_search.parameters.properties.pattern]
# type = "string"
# description = "The regex pattern to search for."

# [tool.grep_search.parameters.properties.path]
# type = "string"
# description = "The directory path to search in."
# default = "."



# --- Internal Prompt Templates ---
# Templates used to construct system prompts for different modes.
# Placeholders like {MAX_TURNS} and {n} are filled at runtime.
[prompts]
# Global system prompt prefix.
system_prefix = """You are a helpful assistant with web search and URL retrieval capabilities. Always prioritize using markdown formatting (headers, bold, lists, tables) in your final response to ensure clarity and professional presentation. Use get_date_time for current date/time if needed (e.g., for 'today' or 'recently'). """

# Prompt appended when force_search is enabled (e.g., --force-search).
force_search = """Unless you are asked to use a specific URL, always use web_search, never try to answer without using web_search. """

# Global system prompt suffix.
system_suffix = """Then use get_url_content for details of the search results. You can pass a list of URLs to get_url_content to fetch multiple pages efficiently at once. Use tools, don't say you can't.You have {MAX_TURNS} turns to complete your task, if you reach the limit, process will be terminated.You should finish your task before reaching %100 of your token limit."""

# Prompt for summarizing the user query.
summarize_query = "Summarize the following query into a single short sentence."

# Prompt for summarizing the final answer.
summarize_answer = """Summarize the following answer into a short paragraph. Be sure to include all numerical values and dates """

# Template for DEEP RESEARCH mode (-d). {n} is the number of searches.
deep_research = """
You are in DEEP RESEARCH mode. You MUST perform at least {n} distinct web searches, or make {n} get_url_content calls to gather comprehensive information before providing a final answer.If you need to get links from a URL, use get_url_details. If you just need to get content from a URL, use get_url_content."""

# Template for DEEP DIVE mode (-dd).
deep_dive = """
You are in DEEP DIVE mode. Use the 'page_crawler' tool exclusively:

1. Start with page_crawler(url="<target>") to fetch initial page content and a numbered link list.
2. Review the returned links (format: "1:link_text, 2:link_text, ...").
3. Request additional pages using page_crawler(link_ids="1,3,5") with comma-separated IDs.
4. Repeat steps 2-3 to explore up to 25 relevant links within the same domain.
5. Base your answer strictly on the retrieved content, not internal knowledge.

IMPORTANT: Only page_crawler is available in this mode.
"""

# --- Model Definitions ---
# Each section [models.NAME] configures a specific model:
#   id: The exact model ID used by the API provider.
#   api: Reference to a name defined in the [api] section.
#   context_size: Total context window size (tokens/chars approximation) for trimming history.

# Note: max_chars is the context_size values of the following models are arbitrarily set for my own use.
# Check model provider's documentation for the actual context size of the models.
# Experiment with max_chars to find the optimal value for your use case (depending on your needs, and model/hardware capabilities)

[models.gf]
id = "gemini-flash-latest"
api = "gemini"
context_size = 1000000

[models.glmair]
id = "glm-4.5-air"
api = "zai"
context_size = 100000

[models.glmflash]
id = "glm-4.7-flash"
api = "zai"
context_size = 100000

[models.q34t]
id = "qwen/qwen3-4b-thinking-2507"
api = "lmstudio"
context_size = 32000

[models.q34]
id = "qwen/qwen3-4b-2507"
api = "lmstudio"
context_size = 32000

[models.lfm]
id = "liquid/lfm2.5-1.2b"
api = "lmstudio"
context_size = 32000

[models.q8]
id = "qwen/qwen3-8b"
api = "lmstudio"
context_size = 32000

[models.q30]
id = "qwen/qwen3-30b-a3b-2507"
api = "lmstudio"
context_size = 32000

# --- Email Settings ---
[email]
smtp_host = "smtp.gmail.com"
smtp_port = 587
# Use smtp_use_ssl = true for port 465 (direct SSL/TLS connection)
# Use smtp_use_tls = true for port 587 (STARTTLS upgrade)
smtp_use_ssl = false
smtp_use_tls = true
# Authentication - use env var (recommended) or direct value
smtp_user_env = "ASKY_SMTP_USER"
smtp_password_env = "ASKY_SMTP_PASSWORD"
# Default sender address (optional, defaults to smtp_user)
from_address = ""

