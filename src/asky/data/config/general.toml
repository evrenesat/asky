# General Settings
[general]
# Name of the environment variable that stores the path to the SQLite history database.
# Default if not set: SEARXNG_HISTORY_DB_PATH
db_path_env_var = "ASKY_DB_PATH"
truncate_messages_in_logs = true
# Logging Configuration
# Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_level = "INFO"
# Log file path. Defaults to ~/.config/asky/logs/asky.log
log_file = "~/.config/asky/logs/asky.log"
# Truncate large messages in debug logs (keeps 20 words on each side)

# Maximum length of the query and answer summaries shown in 'asky -H'.
query_summary_max_chars = 100
answer_summary_max_chars = 2000

# Threshold for using full query vs summary in --continue-chat mode.
# If query length is below this, it's used as is.
continue_query_threshold = 160

# Number of lines of terminal context to fetch and prepend to the query.
# Defaults to 10 lines. Can be overridden via -tl flag.
terminal_context_lines = 10

# Helper to enable compact, two-line banner mode
compact_banner = false

# Global shortlist override for all query modes (true/false). If unset, falls back to
# per-mode settings in [research.source_shortlist].
# shortlist_enabled = true

# URL of your SearXNG instance.
searxng_url = "http://localhost:8888"

# Search provider to be used: "searxng" or "serper"
search_provider = "searxng"

# URL of the Serper API.
serper_api_url = "https://google.serper.dev/search"

# Name of the environment variable that stores the Serper API key.
serper_api_key_env = "SERPER_API_KEY"

# Maximum number of turns (tool calls) allowed in a single conversation loop.
max_turns = 20

# Timeout for API requests in seconds
request_timeout = 60

# Default context size (if not specified in the model configuration)
default_context_size = 4096

# Default model used when no model is specified via CLI (-m).
default_model = ""

# Model used specifically for internal text summarization tasks.
summarization_model = ""

# Model used for interface planning in remote daemon mode.
interface_model = ""

# Model used for image transcription in daemon mode.
default_image_model = ""

# User-Agent string to be used for search and content retrieval requests.
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"

# Specific User-Agent string for LLM API requests.
# Some providers only accept specific user agents for certain subscriptions types.
llm_user_agent = "asky/1.0.0"

# --- Summarizer Settings ---
[summarizer]
# Only summarize past messages (when using -c) if their content length exceeds this many characters.
# Shorter messages will be included in the context as is to save API calls.
lazy_threshold_chars = 2000

# The minimum content length required to trigger the hierarchical (chunked) summarization strategy.
# Content shorter than this but larger than `lazy_threshold_chars` will be summarized in a single pass.
hierarchical_trigger_chars = 4800

# The absolute maximum input length allowed for summarization.
# Any text beyond this character count will be truncated before processing.
hierarchical_max_input_chars = 100000

# The target size for individual semantic chunks when breaking down a long document.
# Increase this if you are using a capable model with a large context window.
hierarchical_chunk_target_chars = 1800

# The number of overlapping characters between chunks.
# This overlap provides context continuity so the model doesn't lose meaning across boundaries.
hierarchical_chunk_overlap_chars = 120

# The maximum character count for the intermediate (map stage) summaries of each chunk.
# Ensures the final reduce step receives concise, manageable inputs.
hierarchical_map_max_output_chars = 750

# --- Limits & Timeouts ---
[limits]
# Maximum number of links returned from get_url_details to prevent context overflow.
max_url_detail_links = 50

# Maximum snippet length in search results.
search_snippet_max_chars = 400

# Maximum recursion depth for expanding slash commands.
query_expansion_max_depth = 5

# Maximum file size for custom prompts read from file (in bytes).
max_prompt_file_size = 10240

# LLM API retry settings
max_retries = 10
initial_backoff = 2
max_backoff = 60

# Search and fetch timeouts in seconds
search_timeout = 20
fetch_timeout = 20

# --- Session Settings ---
[session]
# Trigger compaction at this % of model context
compaction_threshold = 80

# Compaction strategy: "summary_concat" or "llm_summary"
compaction_strategy = "summary_concat"

# If a shell-sticky session has been idle longer than this many minutes,
# the user is prompted to choose: continue, new session, or one-off query.
# Set to 0 to disable the check (always resume automatically).
idle_timeout_minutes = 1
