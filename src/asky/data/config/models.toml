# --- Model Definitions ---
# Each section [models.NAME] configures a specific model:
#   id: The exact model ID used by the API provider.
#   api: Reference to a name defined in the [api] section.
#   context_size: Total context window size (tokens/chars approximation) for trimming history.
#   source_shortlist_enabled: Optional per-model override for pre-LLM source shortlisting.
#     - true: force-enable shortlist for this model
#     - false: force-disable shortlist for this model
#     - unset: use global shortlist settings
#   image_support: Optional boolean capability flag for multimodal image input.
#     - true: model can accept image content arrays (text + image_url base64)
#     - false/unset: model is treated as text-only

# Note: max_chars is the context_size values of the following models are arbitrarily set for my own use.
# Check model provider's documentation for the actual context size of the models.
# Experiment with max_chars to find the optimal value for your use case (depending on your needs, and model/hardware capabilities)

[models.gf]
id = "gemini-flash-latest"
api = "gemini"
context_size = 1000000

[models.glmair]
id = "glm-4.5-air"
api = "zai"
context_size = 100000

[models.glmflash]
id = "glm-4.7-flash"
api = "zai"
context_size = 100000

[models.q34t]
id = "qwen/qwen3-4b-thinking-2507"
api = "lmstudio"
context_size = 32000

[models.q34]
id = "qwen/qwen3-4b-2507"
api = "lmstudio"
context_size = 32000

[models.lfm]
id = "liquid/lfm2.5-1.2b"
api = "lmstudio"
context_size = 32000

[models.q8]
id = "qwen/qwen3-8b"
api = "lmstudio"
context_size = 32000

[models.q30]
id = "qwen/qwen3-30b-a3b-2507"
api = "lmstudio"
context_size = 32000
