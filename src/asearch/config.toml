# asearch Configuration File
# This file defines general settings, API endpoints, user shortcuts, and model configurations.

# --- General Settings ---
[general]
# Name of the environment variable that stores the path to the SQLite history database.
# Default if not set: SEARXNG_HISTORY_DB_PATH
db_path_env_var = "SEARXNG_HISTORY_DB_PATH"

# Maximum length of the query and answer summaries shown in 'asearch -H'.
# These are also passed to the LLM as context when using --continue-chat flag without --full flag.
query_summary_max_chars = 40
answer_summary_max_chars = 200

# URL of your SearXNG instance.
searxng_url = "http://localhost:8888"

# Search provider to be used: "searxng" or "serper"
search_provider = "searxng"

# URL of the Serper API.
serper_api_url = "https://google.serper.dev/search"

# Name of the environment variable that stores the Serper API key.
serper_api_key_env = "SERPER_API_KEY"

# Maximum number of turns (tool calls) allowed in a single conversation loop.
max_turns = 20

# Default model used when no model is specified via CLI (-m).
default_model = "gf"

# Model used specifically for internal text summarization tasks.
summarization_model = "lfm"

# --- API Definitions ---
# Define reusable API endpoints and authentication details here.
# For each section [api.NAME]:
#   url: The base URL for the chat completions endpoint.
#   api_key_env: (Recommended) Name of the environment variable containing the API key.
#   api_key: (Optional) The API key directly. Takes precedence over api_key_env if both are missing.

[api.gemini]
url = "https://generativelanguage.googleapis.com/v1beta/chat/completions"
api_key_env = "GOOGLE_API_KEY"

[api.lmstudio]
url = "http://localhost:1234/v1/chat/completions"
api_key = "lm-studio"


# --- User Prompts (Shortcuts) ---
# Define shortcuts that can be used via '/key' in the CLI.
# Example: 'ask /gn' will be expanded to the prompt below.
[user_prompts]
gn = "Give me latest news from The Guardian, use https://www.theguardian.com/europe"
wh = "how is weather in "
ex = "Explain this: /cp"

# --- Internal Prompt Templates ---
# Templates used to construct system prompts for different modes.
# Placeholders like {MAX_TURNS} and {n} are filled at runtime.
[prompts]
# Global system prompt prefix.
system_prefix = """You are a helpful assistant with web searc and URL retrieval capabilities. Use get_date_time for current date/time if needed (e.g., for 'today' or 'recently'). """

# Prompt appended when force_search is enabled (e.g., --force-search).
force_search = """Unless you are asked to use a specific URL, always use web_search, never try to answer without using web_search. """

# Global system prompt suffix.
system_suffix = """Then use get_url_content for details of the search results. You can pass a list of URLs to get_url_content to fetch multiple pages efficiently at once. Use tools, don't say you can't.You have {MAX_TURNS} turns to complete your task, if you reach the limit, process will be terminated.You should finish your task before reaching %100 of your token limit."""

# Template for DEEP RESEARCH mode (-d). {n} is the number of searches.
deep_research = """
You are in DEEP RESEARCH mode. You MUST perform at least {n} distinct web searches, or make {n} get_url_content calls to gather comprehensive information before providing a final answer.If you need to get links from a URL, use get_url_details. If you just need to get content from a URL, use get_url_content."""

# Template for DEEP DIVE mode (-dd).
deep_dive = """
You are in DEEP DIVE mode. Follow these instructions:
1. Use 'get_url_details' for the INITIAL page to retrieve content and links.
2. Follow up to 25 relevant links within the same domain to gather comprehensive information.
3. IMPORTANT: Use 'get_url_details' ONLY for the first page. Use 'get_url_content' for all subsequent links.
4. Do not rely on your internal knowledge; base your answer strictly on the retrieved content.5. Do not use web_search in deep dive mode."""

# --- Model Definitions ---
# Each section [models.NAME] configures a specific model:
#   id: The exact model ID used by the API provider.
#   api: Reference to a name defined in the [api] section.
#   max_chars: Character limit for content fetched via get_url_content.
#   context_size: Total context window size (tokens/chars approximation) for trimming history.

[models.q34t]
id = "qwen/qwen3-4b-thinking-2507"
api = "lmstudio"
max_chars = 4000
context_size = 32000

[models.q34]
id = "qwen/qwen3-4b-2507"
api = "lmstudio"
max_chars = 4000
context_size = 32000

[models.lfm]
id = "liquid/lfm2.5-1.2b"
api = "lmstudio"
max_chars = 100000
context_size = 32000

[models.q8]
id = "qwen/qwen3-8b"
api = "lmstudio"
max_chars = 4000
context_size = 32000

[models.q30]
id = "qwen/qwen3-30b-a3b-2507"
api = "lmstudio"
max_chars = 3000
context_size = 32000

[models.gf]
id = "gemini-flash-latest"
api = "gemini"
max_chars = 1000000
context_size = 1000000